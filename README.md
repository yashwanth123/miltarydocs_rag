# MilitaryDocs RAG Chatbot

*Question-Answering System Using LangChain, FastAPI, Hugging Face, and Pinecone*

---

## ğŸ“– Project Overview

This project builds a document-based chatbot that retrieves relevant answers from military PDF documents using:

* âœ… Retrieval-Augmented Generation (RAG)
* âœ… Hugging Face LLM (No OpenAI dependency)
* âœ… Pinecone for vector search
* âœ… FastAPI backend

---

## ğŸ—‚ï¸ Project Structure

```
miltarydocs_rag/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ api/                # FastAPI routes
â”‚   â”‚   â””â”€â”€ main.py
â”‚   â”œâ”€â”€ services/           # Query and embedding logic
â”‚   â”‚   â””â”€â”€ embedding_service.py
â”‚   â”œâ”€â”€ utils/              # PDF and text utilities
â”‚   â”‚   â”œâ”€â”€ chunker.py
â”‚   â”‚   â””â”€â”€ pdf_parser.py
â”‚   â””â”€â”€ vector_store/       # Pinecone setup
â”‚       â””â”€â”€ pinecone_client.py
â”‚
â”œâ”€â”€ scripts/                # Setup scripts
â”‚   â”œâ”€â”€ create_index.py
â”‚   â””â”€â”€ ingest_documents.py
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## âš™ï¸ Installation & Setup

1ï¸âƒ£ Clone the repository:

```bash
git clone <your-repo-url>
cd miltarydocs_rag
```

2ï¸âƒ£ Install dependencies:

```bash
pip install -r requirements.txt
```

3ï¸âƒ£ Configure your environment variables:

Create a `.env` file:

```
HUGGINGFACEHUB_API_TOKEN=your_hf_token_here
PINECONE_API_KEY=your_pinecone_key_here
PINECONE_ENV=us-east-1
```

4ï¸âƒ£ Create Pinecone index and ingest documents:

```bash
export PYTHONPATH=.
python scripts/create_index.py
python scripts/ingest_documents.py
```

5ï¸âƒ£ Run the FastAPI server:

```bash
uvicorn backend.main:app --reload
```

6ï¸âƒ£ Test the API:

Visit:

```
http://127.0.0.1:8000/docs
```

Example `curl`:

```bash
curl -X POST "http://127.0.0.1:8000/ask" \
-H "Content-Type: application/json" \
-d '{"query":"What is the military chain of command?"}'
```

---

## âœ… Whatâ€™s Configured:

* Hugging Face Embeddings â†’ `sentence-transformers/all-MiniLM-L6-v2`
* Hugging Face LLM â†’ Configurable via `.env`
* Pinecone vector database with 384 dimensions
* PDF text + OCR extraction
* FastAPI endpoint: `/ask`

---

## âœï¸ Notes

* Tested on Python 3.13
* Hugging Face token is required for private/public LLM access
* If facing version warnings:
  Install:

  ```bash
  pip install -U langchain langchain-community huggingface-hub
  ```

---
